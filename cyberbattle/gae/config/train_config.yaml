# train_config.yaml
# This file contains the training and validation configurations for the GAE model.

model_config: # default NN architecture, not used during hyper-parameters optimization
  layers:
    - type: 'NNConv'
      NN_channels: 16
      out_channels: 64
      activation: 'null'
    - type: 'GCNConv'
      out_channels: 64
      activation: 'null'

learning_rate: 0.01
batch_size: 32

edge_feature_aggregations: # aggregation functions for the edge feature vectors if multiple are present
  - 'mean'

train_iterations: 1000
val_iterations: 300
proportional_cutoff_coefficient: 10
episode_iterations: 100

# all of the following are measured in iterations
switch_interval: 50 # in iterations for the training
val_interval: 300
val_switch_interval: 10

default_vulnerability_embeddings_size: 768

weights: # weights of the different terms in the loss function
  adj_weight: 1 # 2.5
  node_feature_vector_weight: 3 # 24
  edge_feature_vector_weight: 30 # 1.8
  diversity_weight: 200 # 0.1
  node_feature_vector_binary_cat_weight: 6 # 0.9
  node_feature_vector_multi_cat_weight: 6 # 2.23
  node_feature_vector_cont_weight: 3 # 1.8

# NLP extractors have embeddings for vulnerabilities that are in different scales
# Hence continuous features (inside node feature vectors and edge feature vectors) have to be rescaled to have the same weight
nlp_extractors_scalers:
  SecureBERT:
    edge_feature_vector_weight: 3.85
  gpt2:
    edge_feature_vector_weight: 15.5
    node_feature_vector_cont_weight: 2.5
  SecBERT:
    edge_feature_vector_weight: 2.2
  SecRoBERTa:
    edge_feature_vector_weight: 2.2
